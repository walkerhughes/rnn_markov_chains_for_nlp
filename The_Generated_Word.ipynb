{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "The Generated Word.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LW1zM_R88ig"
      },
      "source": [
        "Grant White, Johnson Merrell, Walker Hughes, Alex Shaw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYgq8VH08tBb"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Can we train a computer to write new church hymns? Our project is seeking to answer this question. We will be attempting to recreate both lyrics and music. In this draft we focus on text generation. \n",
        "\n",
        "Text generation has become a hot topic in the past decade, and has begun seeing great success in recent years. Applying these methods to song generation will be a new aspect to explore. Music generation has not seen the same amount of success as text generation, but is still an active field of research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR_ZnKQz95cQ"
      },
      "source": [
        "# Data Cleaning\n",
        "\n",
        "We will use the lyrics from all the Hymns of the Church of Jesus Christ of Latter-day Saints as well as the instrumental tracks. Both of these are available at www.churchofjesuschrist.org. There are 341 hymns available in English.\n",
        "\n",
        "The first step will be processing our data. This will be done in the following five steps:\n",
        "\n",
        "1. Scrape data from online.\n",
        "1. Split each word into it's own line.\n",
        "1. Remove verse numbers.\n",
        "1. Replace sentence-ending punctuation and end of songs with stop words.\n",
        "1. Remove all remaining punctuation.\n",
        "\n",
        "The code for web scraping and data cleaning is given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8lGeWqWUzgg"
      },
      "source": [
        "#initialize url\n",
        "url = 'https://www.churchofjesuschrist.org'\n",
        "hymn = '/study/manual/hymns/the-morning-breaks?lang=eng'\n",
        "\n",
        "#open file\n",
        "with open('lyrics.txt', 'a') as file:\n",
        "    for i in range(341):\n",
        "        # get html code\n",
        "        page_source = requests.get(url + hymn).text\n",
        "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
        " \n",
        "        # print hymn number\n",
        "        print(soup.find(class_='title-number').string)\n",
        "\n",
        "        # get text\n",
        "        current = soup.find_all(class_=\"stanza\")\n",
        "        for verse in current:\n",
        "            lines = verse.strings\n",
        "            for line in lines:\n",
        "                file.write(line + '\\n')\n",
        "            \n",
        "        # update url\n",
        "        if i < 340:\n",
        "            hymn = soup.find(class_='traversalLink-1QVq2 nextLink-1V6GZ').a['href']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TGMuNc08mmx"
      },
      "source": [
        "# Read in our file of lyrics (all songs from the hymn book)\n",
        "filename = 'lyrics.txt'\n",
        "with open(filename) as file:\n",
        "    lyrics = file.read().split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcACz7pOByIC"
      },
      "source": [
        "# Get rid of all the empty strings\n",
        "not_empty = lambda x: len(x) != 0\n",
        "lyrics = list(filter(not_empty, lyrics))\n",
        "\n",
        "# Replace '1.' with end of song word\n",
        "end_of_song = 'END'\n",
        "lyrics = [lyric if lyric != '1.' else end_of_song for lyric in lyrics]\n",
        "lyrics = lyrics[1:]\n",
        "lyrics.append(end_of_song)\n",
        "\n",
        "# Strip out all the verse numbers\n",
        "not_verse_num = lambda x: not (x[0].isnumeric() and x.endswith('.'))\n",
        "lyrics = list(filter(not_verse_num, lyrics))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOPtH2WEB066"
      },
      "source": [
        "# Replace all periods with a stop word\n",
        "period = 'PERIOD'\n",
        "exclamation = 'EXCLAMATION'\n",
        "question = 'QUESTION'\n",
        "semi_colon = 'SEMI'\n",
        "\n",
        "stop_lyrics = []\n",
        "\n",
        "for lyric in lyrics:\n",
        "    if lyric.endswith('.'):\n",
        "        lyric = lyric.replace('.', '')\n",
        "        stop_lyrics.append(lyric)\n",
        "        stop_lyrics.append(period)\n",
        "    elif lyric.endswith(';'):\n",
        "        lyric = lyric.replace(';', '')\n",
        "        stop_lyrics.append(lyric)\n",
        "        stop_lyrics.append(semi_colon)\n",
        "    elif lyric.endswith('!'):\n",
        "        lyric = lyric.replace('!', '')\n",
        "        stop_lyrics.append(lyric)\n",
        "        stop_lyrics.append(exclamation)\n",
        "    elif lyric.endswith('?'):\n",
        "        lyric = lyric.replace('?', '')\n",
        "        stop_lyrics.append(lyric)\n",
        "        stop_lyrics.append(question)\n",
        "    else:\n",
        "        stop_lyrics.append(lyric)\n",
        "\n",
        "lyrics = stop_lyrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MVzAPGQB4v0"
      },
      "source": [
        "def process_lyric(lyric):\n",
        "    \"\"\"\n",
        "    Gets rid of punctuation and non-latin characters\n",
        "    \"\"\"\n",
        "    apostrophe = 'â\\x80\\x99'\n",
        "    a_hat = 'â'\n",
        "    lyric = lyric.replace(apostrophe, '')\n",
        "    lyric = lyric.replace(a_hat, '') \n",
        "    lyric = ''.join([char for char in lyric if char.isalpha()])\n",
        "\n",
        "    return lyric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5lxLXpSB8kI"
      },
      "source": [
        "# Get rid of punctuation and non-latin characters\n",
        "lyrics = list(map(process_lyric, lyrics))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFUGW8FWB-rV"
      },
      "source": [
        "# Write the cleaned lyrics\n",
        "filename = 'clean_lyrics.txt'\n",
        "with open(filename, 'w') as file:\n",
        "    for lyric in lyrics:\n",
        "        lyric += '\\n'\n",
        "        file.write(lyric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zpKMubCEKD6"
      },
      "source": [
        "# Methods\n",
        "\n",
        "To produce a hymn we generate lyrics and music through distinct processes. For lyrics we use a Markov chain, transformer, and recurrent neural network (RNN). For music, we experiment with a traditional RNN and generative adversarial network (GAN).\n",
        "\n",
        "## Lyrics\n",
        "A Markov chain is a straightforward and obvious model to use for generating random text to resemble a given corpus. Markov chains are simple to implement, quick to train on small corpuses, and easy to explain to others. Unfortunately, these benefits come at a cost – because our model is _Markov_, it only takes into consideration one word or lyric at a time when predicting the next. We implemented our own model using a dictionary, with the key being a word or lyric, and the value being a list of non-unique words that follow the key in the corpus. We include this code below:\n",
        "\n",
        "```\n",
        "filename = 'clean_lyrics.txt'\n",
        "with open(filename) as file:\n",
        "    lyrics = file.read().split()\n",
        "\n",
        "for word1, word2 in pairs:\n",
        "    if word1 in word_dict.keys():\n",
        "        word_dict[word1].append(word2)\n",
        "    else:\n",
        "        word_dict[word1] = [word2]\n",
        "\n",
        "# Find all potential start words and pick a random one\n",
        "start_words = [word for word in lyrics if (word[0].upper() == word[0]) and word not in stop_words]\n",
        "\n",
        "stop_words = {\n",
        "    'PERIOD': '.',\n",
        "    'EXCLAMATION': '!',\n",
        "    'QUESTION': '?',\n",
        "    'SEMI': ';',\n",
        "    'END': '',\n",
        "}\n",
        "\n",
        "def generate_text(start_word):\n",
        "    \"\"\"Generates text.\"\"\"\n",
        "    sentence = [start_word]\n",
        "    word = start_word\n",
        "    while True:\n",
        "        word = np.random.choice(word_dict[word])\n",
        "        if word in stop_words:\n",
        "            sentence.append(stop_words[word])\n",
        "            if word == 'END':\n",
        "                break\n",
        "        else:\n",
        "            sentence.append(' ' + word)\n",
        "\n",
        "    return ''.join(sentence)\n",
        "\n",
        "start_word = np.random.choice(start_words)\n",
        "generate_text(start_word)\n",
        "```\n",
        "\n",
        "We also use a highly optimized package for constructing Markov chains for this exact use called `markovify`. This package makes it extremely easy to build and use Markov chains trained on small and medium-sized corpuses.\n",
        "\n",
        "```\n",
        "import markovify\n",
        "\n",
        "with open(\"./cleaned_lyrics.txt\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "text_model = markovify.Text(text)\n",
        "    \n",
        "print(text_model.make_short_sentence(100))\n",
        "```\n",
        "\n",
        "Note that the `.make_short_sentence(N)` method generates a sentence with `N` characters or less.\n",
        "\n",
        "\n",
        "For our Recurrent Neural Network (RNN) we used the char-rnn originally developed by Andrej Karpathy. This RNN creates sequences of words after being trained probabilistically on sequences of characters. The RNN then can be sampled to generate new sequences of text that are similar to the text it was trained on. \n",
        "\n",
        "RNN models are generally ideal for time-series and sequential data, so this RNN will fit our purposes since our song lyrics will be temporally dependent on previous lyrics. We trained this model on the lyrics from the LDS Hymnbook and then samples text in order to generate new lyrics. \n",
        "\n",
        "```\n",
        "def train(inp, target):\n",
        "\n",
        "    hidden = decoder.init_hidden()\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    # iterate through input characters and target characters \n",
        "    for input_char, target_char in zip(inp, target):\n",
        "        target_char = target_char.unsqueeze(0) # correct the size \n",
        "        out_char, hidden = decoder(input_char, hidden) # decode \n",
        "        out_char = out_char.squeeze(0) # reshape \n",
        "        loss += criterion(out_char, target_char) # update loss \n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "    # return the loss \n",
        "    return loss.item() / len(inp) \n",
        "```\n",
        "\n",
        "\n",
        "## Music\n",
        "\n",
        "# Results\n",
        "We achieve mixed results from our different approaches.\n",
        "\n",
        "## Lyrics\n",
        "Our own implementation of a Markov model worked surprisingly well. Below is an example of 10 sentences we generated.\n",
        "\n",
        "```\n",
        "Which with lively praise Our souls with my toilsome way.\n",
        "For joys and pure in our shield Is far abroad To thee.\n",
        "Half its firmrooted bulwarks outstand the angels sayÂ Alleluia!\n",
        "Oh wilt thou art so pleasant hours defend me? \n",
        "Ever guard us to bestow. \n",
        "Now Ill sing to his holy name be Nearer nearer That which he suffered grief is before him home.\n",
        "Guide me an endless day. \n",
        "Go search more will be our minds with love at my breast. \n",
        "Rise ye heavnly fire and wear; Come cast the gospels sound. \n",
        "His precious grain and sing Alleluia!\n",
        "```\n",
        "\n",
        "The `markovify` implementation of the Markov model seemed to work qualitatively better. This implementation seemed to have more cohesive sentences than our own. Below are 10 sentences it generated.\n",
        "\n",
        "```\n",
        "Jesus, our only joy be thou, As thou our glory now, And thru eternity.\n",
        "In mem'ry of thy providence more?\n",
        "Angels of glory unto thee.\n",
        "Come unto Jesus; He'll surely hear you, Jew and Gentile greet the sound.\n",
        "We love thy glad tidings by sea and main.\n",
        "Help us all to thy keep.\n",
        "How vast is our mission, If we now at parting One more strain of praise.\n",
        "I kneel upon the windy hill; Seeds that live and glory to his name!\n",
        "Savior, may I repose And wake with praises to his name.\n",
        "Glorious things of thee are led In rev'rence sweet.\n",
        "```"
      ]
    }
  ]
}